{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkhH7X2D46VXAs+GVBh2/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzoR21/Computer-Vision-Project/blob/main/notebook/parking_slot_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-time Parking Slot Occupancy Detection\n",
        "\n",
        "---\n",
        "\n",
        "## üìò Overview\n",
        "This is a supporting secondary notebook, which contains the definition and training of a model that extracts the coordinates of individual parking slots from entire images of parking spaces. The pre-trained FasterRCNN-FPN model from pytorch is used as the model.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Authors\n",
        "- **Lorenzo Russo**  \n",
        "  Email: russo.2091186@studenti.uniroma1.it\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Useful Links\n",
        "- [Project Repository](https://github.com/lorenzoR21/Computer-Vision-Project)\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w8CwOc4y4JVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all needed library"
      ],
      "metadata": {
        "id": "_D08P4w-4Oba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "WUWhqDan4bcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all needed library"
      ],
      "metadata": {
        "id": "byGn6_Em4RAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from torchmetrics.classification import Accuracy, AUROC\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset, random_split\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "wdaGT7zn4d4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "8rONCHuh4WqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/fabiocarrara/deep-parking/releases/download/archive/CNR-EXT_FULL_IMAGE_1000x750.tar\" -O \"CNRPark_FULL_IMAGE.tar\"\n",
        "!mkdir CNR-EXT_FULL_IMAGE_1000x750\n",
        "!tar -xf CNRPark_FULL_IMAGE.tar -C CNR-EXT_FULL_IMAGE_1000x750 && rm CNRPark_FULL_IMAGE.tar"
      ],
      "metadata": {
        "id": "ztefX2x_4Jxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EntireParkingDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.annotation_dir = annotation_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = self._get_image_files()\n",
        "        self.annotations = self._load_annotations()\n",
        "\n",
        "    def _get_image_files(self):\n",
        "        image_files = []\n",
        "        for date_dir in os.listdir(self.root_dir):\n",
        "            date_path = os.path.join(self.root_dir, date_dir)\n",
        "            if os.path.isdir(date_path):\n",
        "                for camera_dir in os.listdir(date_path):\n",
        "                    camera_path = os.path.join(date_path, camera_dir)\n",
        "                    if os.path.isdir(camera_path):\n",
        "                        for img_file in os.listdir(camera_path):\n",
        "                            if img_file.endswith('.jpg'):\n",
        "                                image_files.append((int(camera_path[-1]), os.path.join(camera_path, img_file)))\n",
        "        return image_files\n",
        "\n",
        "    def _load_annotations(self):\n",
        "        annotations = {}\n",
        "        scale_factor_x = 1000 / 2592\n",
        "        scale_factor_y = 750 / 1944\n",
        "        for camera in range(1, 10):\n",
        "            annot_path = os.path.join(self.annotation_dir, f'camera{camera}.csv')\n",
        "            df = pd.read_csv(annot_path)\n",
        "            for _, row in df.iterrows():\n",
        "                slot_id = row['SlotId']\n",
        "                x_large, y_large, w_large, h_large = int(row['X']), int(row['Y']), int(row['W']), int(row['H'])\n",
        "\n",
        "                x_small = int(x_large * scale_factor_x)\n",
        "                y_small = int(y_large * scale_factor_y)\n",
        "                w_small = int(w_large * scale_factor_x)\n",
        "                h_small = int(h_large * scale_factor_y)\n",
        "\n",
        "                left = x_small\n",
        "                upper = y_small\n",
        "                right = x_small + w_small\n",
        "                lower = y_small + h_small\n",
        "\n",
        "                if camera not in annotations:\n",
        "                    annotations[camera] = []\n",
        "                annotations[camera].append([left, upper, right, lower])\n",
        "        return annotations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        camera, img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        b = self.annotations.get(camera, [])\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for slot in b:\n",
        "            x1, y1, x2, y2 = slot\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "            labels.append(1)\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "        if self.transform:\n",
        "            image, target = self.transform(image, target)\n",
        "\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "zmEsOCew63Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Resize:\n",
        "    def __init__(self, size=(450, 600)):\n",
        "        self.size = size\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(self.size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image, target=None):\n",
        "        w, h = image.size\n",
        "        image = self.transform(image)\n",
        "        new_h, new_w = self.size\n",
        "\n",
        "        if target:\n",
        "            boxes = target['boxes']\n",
        "            boxes[:, 0] = boxes[:, 0] * (new_w / w)\n",
        "            boxes[:, 1] = boxes[:, 1] * (new_h / h)\n",
        "            boxes[:, 2] = boxes[:, 2] * (new_w / w)\n",
        "            boxes[:, 3] = boxes[:, 3] * (new_h / h)\n",
        "            target['boxes'] = boxes\n",
        "\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "transform = Resize()"
      ],
      "metadata": {
        "id": "4r89j03VjW_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sunny = EntireParkingDataset(root_dir='CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/SUNNY', annotation_dir='CNR-EXT_FULL_IMAGE_1000x750', transform=transform)\n",
        "dataset_rainy = EntireParkingDataset(root_dir='CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/RAINY', annotation_dir='CNR-EXT_FULL_IMAGE_1000x750', transform=transform)\n",
        "dataset_overcast = EntireParkingDataset(root_dir='CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/OVERCAST', annotation_dir='CNR-EXT_FULL_IMAGE_1000x750', transform=transform)\n",
        "dataset = ConcatDataset([dataset_sunny, dataset_rainy, dataset_overcast])\n",
        "\n",
        "total_length = len(dataset)\n",
        "train_length = int(0.7 * total_length)\n",
        "val_length = int(0.1 * total_length)\n",
        "test_length = total_length - train_length - val_length\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_length, val_length, test_length])\n",
        "\n",
        "train_dataset.transforms = transform\n",
        "val_dataset.transforms = transform\n",
        "test_dataset.transforms = transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "2Z-h6Ikp7VqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Parking Slot with FasterRCNN_FPN"
      ],
      "metadata": {
        "id": "6rkaS7Rr4ysB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jzjXoBk5LGLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParkingSlotDetectionModel(pl.LightningModule):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ParkingSlotDetectionModel, self).__init__()\n",
        "        self.model = get_model(num_classes)\n",
        "\n",
        "    def forward(self, images, targets=None):\n",
        "        if targets:\n",
        "            output = self.model(images, targets)\n",
        "            return output\n",
        "        return self.model(images)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, targets = batch\n",
        "        images = list(image for image in images)\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        loss_dict = self.forward(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        self.log('train_loss', losses)\n",
        "        return losses\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, targets = batch\n",
        "        images = list(image for image in images)\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        self.model.train()\n",
        "        with torch.no_grad():\n",
        "            loss_dict = self.forward(images, targets)\n",
        "        self.model.eval()\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        self.log('val_loss', losses)\n",
        "        return losses\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, targets = batch\n",
        "        images = list(image for image in images)\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        self.model.train()\n",
        "        with torch.no_grad():\n",
        "            loss_dict = self.forward(images, targets)\n",
        "        self.model.eval()\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        self.log('test_loss', losses)\n",
        "        return losses\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "        return [optimizer], [lr_scheduler]"
      ],
      "metadata": {
        "id": "IJWZgLW5LYZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_logger = TensorBoardLogger('logs/', name='parking_slot_detection')"
      ],
      "metadata": {
        "id": "cdybOfdvhfRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ParkingSlotDetectionModel(num_classes=2)\n",
        "trainer = Trainer(max_epochs=10, accelerator='gpu', devices=1 if torch.cuda.is_available() else 0, logger=tb_logger)"
      ],
      "metadata": {
        "id": "uEZ90my9heoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "RWjH-MEi5nDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "ioiRIZouChwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model"
      ],
      "metadata": {
        "id": "V0LEOiiC5rDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model, test_loader)"
      ],
      "metadata": {
        "id": "xYZLASoDCsi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained model"
      ],
      "metadata": {
        "id": "4_WMPqgU5syo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'parking_slot_detection.pth')"
      ],
      "metadata": {
        "id": "HJ3vxovgZOIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze loss and metrics"
      ],
      "metadata": {
        "id": "mv4UJN685wrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "cSpw1T1sh5K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "9HKehHVBh6ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/"
      ],
      "metadata": {
        "id": "tZqBpvsih82E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}